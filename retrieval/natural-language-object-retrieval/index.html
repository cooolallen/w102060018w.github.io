<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yuan-Hong Liao</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Homepage and blog">
    <meta name="author" content="Yuan-Hong Liao">
    <meta name="keywords" content="object_detection">
    <link rel="canonical" href="https://andrewliao11.github.io/retrieval/natural-language-object-retrieval/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Yuan-Hong Liao" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201602132020" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Verifications -->
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Video Object Detection using Faster R-CNN">
    <meta property="og:description" content="Homepage and blog">
    <meta property="og:url" content="https://andrewliao11.github.io/retrieval/natural-language-object-retrieval/">
    <meta property="og:site_name" content="Yuan-Hong Liao">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@andrewliao11" />
    
    <meta name="twitter:title" content="Natural Language Object Retrieval" />
    <meta name="twitter:description" content="Homepage and blog" />
    <meta name="twitter:url" content="https://andrewliao11.github.io/retrieval/natural-language-object-retrieval/" />

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-63278661-1']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    
</head>

<body class="site">
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="https://andrewliao11.github.io" class="site-title"></a>
      <nav class="site-nav">
        <a href="/">Home</a>
<a href="/research/">Research</a>
<a href="/blog/">Blog</a>
      </nav>
      <div class="clearfix" ></div>
      
        <div class="social-icons">
  <div class="left">
    
      <a class="fa fa-github" href="https://github.com/andrewliao11"></a>
    
    
    <a class="fa fa-rss" href="/feed.xml"></a>
    
      <a class="fa fa-twitter" href="https://twitter.com/andrewliao11"></a>
    
    
      <a class="fa fa-google-plus" href="https://plus.google.com/+andrewliao11/posts"></a>
    
    
      <a class="fa fa-linkedin" href="https://www.linkedin.com/in/andrewliao11"></a>
    
    
    
  </div>
  <div class="right">

    
    
    
  </div>
</div>

<div class="clearfix">
    
      <center> <a class="fa fa-envelope" href="mailto:andrewliao11@gmail.com"></a> andrewliao11@gmail.com <center>
    
</div>

    

      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h1>Natural Language Object Retrieval<Down></h1>
  <span class="post-meta">Aug 30, 2016</span><br>
  <span class="post-meta small">
    Ground the object via Natural Language (referring expression)
  </span>
</div>

<article class="post-content">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<p>This article is about the work that I focused on in <a href="https://www.umbocv.com">UmboCV</a> internship. I'll show 
some survey on natural language object retrieval and similar topic: referring expression. Besides, I released the tensorflow 
implementation of <a href="https://github.com/andrewliao11/Natural-Language-Object-Retrieval-tensorflow">Natural 
Language Object Retrieval</a> (<a href="http://arxiv.org/abs/1511.04164">paper link</a>).</p>

<h2>Backgound</h2>
<p>Object detection is an age-old question. Many application need the techniques of object detection, such as IoT, 
self-driving car. So here we're gonna introduce the state-of-the-art: faster rcnn, achieves high performance and can be 
used in real-time.</p>

<h4><a href="http://arxiv.org/abs/1311.2524">Region-based Convolutional Neural Network</a></h4>
Region-based Convolutional Neural Network, aka R-CNN, is a visual object detection system that combines 
bottom-up region proposals with features computed by a convolutional neural network.</br> 
R-CNN first computes the region proposal with techniques, such as selective search, and feeds the candidates to the 
convolutional neural network to do the classification task. Here's the system flow of R-CNN: 
<p><img src="/images/faster_rcnn/rcnn_network.png" alt="mdp" /></p> 
However, it can some notable disadvantages:
<ol>
  <li>Training is a multi-stage pipeline.(three training stages) </li>
  <li>Training is expensive in space. (due to the multi-stage training pipeline)</li>
  <li>Object detection is slow. Detection with VGG16 takes 47s / image (on a GPU).</li>
</ol>
R-CNN is slow because it performs a ConvNet forward pass for each object proposal, without sharing computation. Many 
works have been proposed to solve this problem, such as <a href="https://arxiv.org/abs/1406.4729">spatial pyramid 
pooling networks(SPPnets)</a>, whcih tries to avoid repeatedly computing the convolutional features.</br>
Thus, R-CNN is not good enough for us in application uses though it provides bare enough performance.

<h4><a href="http://arxiv.org/abs/1504.08083">Fast R-CNN</a></h4>
<p>"Fast" R-CNN is quite easy to understand by its word. It's quite fast, achieving 0.3s per image for detection when ignoring 
the region proposal. Well, how does this magic works? </br>
The most important factor is that it shares the computation. After the region proposal, we'll get some bounding boxes. In the previous
alogrithm, they just directly feed the warped image to the CNN. That is, if we have 2000 proposals, we have to do 2000 times 
forward pass, which wasting lots of time. Actually, we can use the relation between these proposals. Many proposals have overlap 
with others, and these overlap part is fed into the CNN for many times. Maybe we can just compute them for once.</br>
Fast R-CNN utilizes this property well. Here's the illustration of how it really works:</br></p>
<p><img src="/images/faster_rcnn/fast_rcnn_network.png" alt="RL" /></p>
<p>First, we'll feed the whole image into the ConvNet (to conv5). Then, it's where the magic lies in: we know that convolutional 
layer won't change the spatial relation between the adjacent pixels. That is, the upmost pixel will still falls on the upmost
part of the feature map in conv5. Based on this, it's possible for us to porject the coordinates in raw image to the corresponding
neuron in conv5! In this way, we can just compute the image through ConvNet once. After getting the faeture for each bounnding box, 
it will be fed into the RoI pooling layer, which is a special-case of the spatial pyramid pooling layer. The rest work is similar 
to the previous work.</br>
The following figure is a more clear illustration of Fast R-CNN:</br></p>
<p><img src="/images/faster_rcnn/illustration_frcnn.png" alt="RL" /></p>

<h2><a href="http://arxiv.org/abs/1506.01497">Faster R-CNN</a></h2>
<p>What is Faster R-CNN?</br> Yes! you're right. It's a faster versino of Fast R-CNN.(The author is quite a straight guy, right?)
Faster R-CNN brings the object detection toward the real-time application. It achieves 10 ms per image for object detection 
including time cost in region proposal. If you know well about Fast R-CNN, Faster-R-CNN won't be too difficult for you. It replace 
the previous region proposal method with a so-called "Region Proposal Netwrok", aka RPN, making the whole network complete. The 
Faster R-CNN is look like this:<br></p>
<p><img src="/images/faster_rcnn/faster_rcnn_netwrok.png" alt="RL" /></br>Left: the overview of the Faster R-CNN network. 
Right: the region proposal network. Different anchors will apply to the sliding window.</p>
<p>A Region Proposal Network (RPN) takes an image feature map as input and outputs a set of rectangular object
proposals, each with an objectness score. Faster R-CNN model this process with a fully convolutional network. The 
RPN network will detect whether the current region (generated from sliding window and different anchors) is thing 
or stuff (objectness score) and do the bounding box regression.</p>
<h3>How does RPN work?</h3>
<p>Usually, the RPN takes image feature map as input(conv5 in Alexnet). And we will apply a 3*3 sliding window on the 
feature map. Noted that though the window size here is only 3*3, the actual receptive field is quite large if you project 
the coordinate back to the raw input size. This operation is done by applying an 3*3*256 convolutional kernel on the feature map. 
In this way, we will get a intermediate layer in 256 dimension. Then the intermediate layer will feed into two different 
branches, one for objectness score(determines whether the region is thing or stuff) and the other for regression(determines 
how should the bounding box change to become more similar to the ground truth box).</p>

<h4>Some conclusion:</h4>
<p>Right now Faster R-CNN provides us a real-time algorithm for object detection. We'll see more devices with this techniques, such
 as surveillance camera, mobile device. Or we can even extend the object detection on images to object detection on videos, 
 which is more useful for our lifes.</p></p>
 
<h2>Train Faster R-CNN on your own dataset(eg. ImageNet)</h2>
<p>Faster R-CNN is a really cool stuff. You can see my <a href="https://www.youtube.com/watch?v=wY7LADoEuFs">demo video</a>, which 
is pretty amazin, right. It can even detect the swimming trunk! If you want to train Faster R-CNN on your own dataset, you can 
refer to <a href="https://github.com/andrewliao11/py-faster-rcnn/blob/master/README.md">my tutorial</a>.</br>
Here is my result on ImageNet, which I train on validation set 1 and test on validation set 2.</p>
<p><img src="/images/faster_rcnn/mAP_200.png" alt="RL" /></br>I got 33.1% mAP on ImageNet 200 categories</p>



<h2>Reference:</h2>
Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun, <a href="http://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time
Object Detection with Region Proposal Networks</a><br>
Ross Girshick, <a href="http://arxiv.org/abs/1504.08083">Fast R-CNN</a><br>
Ross Girshick Jeff Donahue Trevor Darrell Jitendra Malik, <a href="https://arxiv.org/pdf/1311.2524.pdf">Rich feature hierarchies for
accurate object detection and semantic segmentation</a><br>

</article>


  





  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'fasterrcnn';
    var disqus_identifier = '/object_detection/faster_rcnn';
    var disqus_title      = '';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://pixyll.com/">Pixyll</a> theme. Hosted on <a href="https://pages.github.com/">Github Pages</a>. <br>
      © Yuan-Hong Liao
    </small>
  </div>
</footer>

</body>
</html>
