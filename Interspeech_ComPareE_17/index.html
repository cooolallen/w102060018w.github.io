<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Huiting Hong</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Homepage and blog">
    <meta name="author" content="Huiting Hong">
    
    <link rel="canonical" href="https://w102060018w.github.io/blog/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Avi Singh" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201602132020" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Verifications -->
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Blog">
    <meta property="og:description" content="Homepage and blog">
    <meta property="og:url" content="https://w102060018w.github.io/blog/">
    <meta property="og:site_name" content="Huiting Hong">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@w102060018w" />
    
    <meta name="twitter:title" content="Blog" />
    <meta name="twitter:description" content="Homepage and blog" />
    <meta name="twitter:url" content="https://w102060018w.github.io/blog/" />

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-63278661-1']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    
</head>

<body class="site">
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="https://w102060018w.github.io" class="site-title"></a>
      <nav class="site-nav">
        <a href="/">Home</a>
<a href="/research/">Research</a>
<a href="/blog/">Blog</a>
      </nav>
      <div class="clearfix" ></div>
      
        <div class="social-icons">
  <div class="left">
    
      <a class="fa fa-github" href="https://github.com/w102060018w"></a>
    
    
      <a class="fa fa-twitter" href="https://twitter.com/w102060018w"></a>
    
    
      <a class="fa fa-linkedin" href="https://www.linkedin.com/in/huiting-hong-a591a9129/"></a>
    
    
    
  </div>
  <div class="right">

    
    
    
  </div>
</div>

<div class="clearfix">
    
      <center> <a class="fa fa-envelope" href="mailto:w102060018w@gmail.com"></a> w102060018w@gmail.com <center>
    
</div>

    

      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h1>Interspeech 2017 ComPareE<Down></h1>
  <span class="post-meta">Mar 30, 2017</span><br>
<!--   <span class="post-meta small">
    Basic concept on 
  </span> -->
</div>

<article class="post-content">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<p>I start working on this challenge around Feb. 2017 with other members in our <a href="http://biic.ee.nthu.edu.tw/">lab</a>. We plan to apply several traditional procedures on detecting audio signal with specific characteristic and try other distinctive approaches to see if they will get better results. In this article, I will give a brief concept of different encoding approach, including BOW, GMM along with Fisher Vector. Also I will show some detail on strength model. Finally show the results we get in this challenge. </p>

<h2>Commonly used encoding approaches</h2>
<h4>BOW(Bag of Words)</h4>
<p>Bag of words is an approach which can reduce the dimension of features processed from raw data. The brief concept can be devided into two parts, one is to decide the criteria of categorization and the other is to generate histogram base on the criteria:</br>
Suppose we have already processed our raw data (audio signal) and get the NxD dimension features.  
<h5>Decide the criteria of cluster-categorization</h5>
Sometimes we also say it's just like making a vocabulary codebook, which can later be used at counting the amount of each word.<br/> 
The idea started at using kmeans method to generate numbers of k centrol points of k-clusters respectively. If nowadays we have mutiple features, F<sub>i</sub>, whose dimension are all NxD, we can randomly sample equal amount of rows from F<sub>i</sub> and generate the center point of each cluster base on the information in different features. In this way, the center point we create of each cluster can be more valid on different feature, and let the later categorized-result(histogram) to be more representative and convincing.
<h5>Generate histogram</h5>
After we got the center point of each cluster, we can categorize our features into different clusters. Each features, F<sub>i</sub>, will have a categorization result, showing the amount of pieces belongs to each cluster.(Due to the dimension of F<sub>i</sub> is NxD, we can know that there are totally N pieces in the feature F<sub>i</sub>). Finally, the 'voting' result can also be seen as a histogram, which x-axis represents k-cluster and y-axis represents the number of pieces belongs to each cluster.</br>
The generated histogram is then used to describe the origianl features, which reduce the dimension from NxD to 1xD. 
<p>In short, BOW approach can help us to encode the feature into a more representative while low-dimension result.</p>
</br>
Here's the flow:</br>
<img src="/images/Interspeech_2017/BOW.png" alt="model-nlor" />


<h4>GMM and Fisher Vector</h4>
<p></p>
<!-- 
Here's the illustration: </p>
<p><img src="/images/retrieval/illustration.png" alt="illustration" /></p>
<p>The blue box represents the ground truth, while the yellow stands for positive recall, red for negative recall.</p>

<h2>Overview:</h2>
<ol>
  <li>Natural Language Object Retrieval </li>
  <li>Grounding with supervised training + multi-task loss</li>
  <li>Grounding + region proposal network</li>
</ol>

<h4>1. Natural Language Object Retrieval, inspired by <a href="http://arxiv.org/abs/1511.04164">Ronghang Hu's work</a></h4>
<p>This work was appeared in cvpr 2016. It extend the previous work, <a href="https://arxiv.org/abs/1411.4389">LRCN</a>, use 
the same way to generate caption. Compare the predicted caption with the query, and find the most related one. I call the whole 
process "reconstruction", which means that the model try to reconstruct back the query based on the bbox feature.</br>
Here's the model:</br>
<img src="/images/retrieval/natural-language-object-retrieval-model.png" alt="model-nlor" />
Noted that the model generate the caption not onlt based on the bbox feature, but also on the context feature, though it's a relatively
 naive way to use the context information. The paper also mentions the w/o context feature perormance:</br>
<img src="/images/retrieval/exp.png" alt="exp-nlor" /></p>

<h4>2. Grounding with supervised training + multi-task loss, inspired by <a href="https://arxiv.org/abs/1511.03745">
    Anna Rohrbach's work</a></h4>
<p>This work is from the same team of UC Berkeley. It extends the work to three different models, unsupervised, semi-supervised, and 
fully supervised model. Basically, it also uses the concept of reconstruction and combine it with a more direct way: directly choose
 the most related region. Furthermore, in the unsupervised model, they also use the attention mechanism, which is used heavily in 
 image caption task.<\br>
Here, I modified the fully supervised method with an extra reconstruction loss. This make the whole model become like a multi-task 
model, which increase the performance about 2%! The following is what the model look like:<\br>
<img src="/images/retrieval/model2.png" alt="model2" />
</p>

<h2>Acknowledgement:</h2>
<p>This work is done during my Umbo CV internship. Thanks to all the umbots that fulfills my summer internship. Umbo CV really 
provides a comfortable environment for coders. I truely enjoy the life there. :)
</p>
<h2>Reference:</h2>
Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko, Trevor Darrell, <a href="http://arxiv.org/abs/1511.04164">Natural Language Object Retrieval</a><br>
Anna Rohrbach, Marcus Rohrbach, Ronghang Hu, Trevor Darrell, Bernt Schiele, <a href="https://arxiv.org/abs/1511.03745">Grounding of Textual Phrases in Images by Reconstruction </a><br>
Sahar Kazemzadeh, Vicente Ordonez Mark Matten, Tamara Berg, <a href="http://tamaraberg.com/referitgame/">ReferItGame: Referring to Objects in Photographs of Natural Scenes </a><br> -->

</article>

  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'http-w102060018w-github-io';
    var disqus_identifier = '/Interspeech_ComPareE_17';
    var disqus_title      = '';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://pixyll.com/">Pixyll</a> theme. Hosted on <a href="https://pages.github.com/">Github Pages</a>. <br>
      Â© Yuan-Hong Liao
    </small>
  </div>
</footer>

</body>
</html>
