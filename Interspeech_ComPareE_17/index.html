<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Huiting Hong</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Homepage and blog">
    <meta name="author" content="Huiting Hong">
    
    <link rel="canonical" href="https://w102060018w.github.io/blog/">
    <link rel="alternate" type="application/rss+xml" title="RSS Feed for Avi Singh" href="/feed.xml" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/pixyll.css?201602132020" type="text/css">

    <!-- Fonts -->
    <link href='//fonts.googleapis.com/css?family=Merriweather:900,900italic,300,300italic' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Lato:900,300' rel='stylesheet' type='text/css'>
    
      <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet">
    

    <!-- Verifications -->
    

    <!-- Open Graph -->
    <!-- From: https://github.com/mmistakes/hpstr-jekyll-theme/blob/master/_includes/head.html -->
    <meta property="og:locale" content="en_US">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Blog">
    <meta property="og:description" content="Homepage and blog">
    <meta property="og:url" content="https://w102060018w.github.io/blog/">
    <meta property="og:site_name" content="Huiting Hong">

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    
        <meta name="twitter:site" content="@w102060018w" />
    
    <meta name="twitter:title" content="Blog" />
    <meta name="twitter:description" content="Homepage and blog" />
    <meta name="twitter:url" content="https://w102060018w.github.io/blog/" />

    <!-- Icons -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-63278661-1']);
      _gaq.push(['_trackPageview']);
      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    
</head>

<body class="site">
  <div class="site-wrap">
    <header class="site-header px2 px-responsive">
  <div class="mt2 wrap">
    <div class="measure">
      <a href="https://w102060018w.github.io" class="site-title"></a>
      <nav class="site-nav">
        <a href="/">Home</a>
<a href="/research/">Research</a>
<a href="/blog/">Blog</a>
      </nav>
      <div class="clearfix" ></div>
      
        <div class="social-icons">
  <div class="left">
    
      <a class="fa fa-github" href="https://github.com/w102060018w"></a>
    
    
      <a class="fa fa-twitter" href="https://twitter.com/w102060018w"></a>
    
    
      <a class="fa fa-linkedin" href="https://www.linkedin.com/in/huiting-hong-a591a9129/"></a>
    
    
    
  </div>
  <div class="right">

    
    
    
  </div>
</div>

<div class="clearfix">
    
      <center> <a class="fa fa-envelope" href="mailto:w102060018w@gmail.com"></a> w102060018w@gmail.com <center>
    
</div>

    

      
    </div>
  </div>
</header>


    <div class="post p2 p-responsive wrap" role="main">
      <div class="measure">
        


<div class="post-header mb2">
  <h1>Interspeech 2017 ComPareE<Down></h1>
  <span class="post-meta">Mar 30, 2017</span><br>
<!--   <span class="post-meta small">
    Basic concept on 
  </span> -->
</div>

<article class="post-content">
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<p>I start working on this challenge around Feb. 2017 with other members in our <a href="http://biic.ee.nthu.edu.tw/">lab</a>. We plan to apply several traditional procedures on detecting audio signal with specific characteristic and try other distinctive approaches to see if they will get better results. In this article, I will give a brief concept of different encoding approach, including BOW, GMM along with Fisher Vector. Also I will show some detail on strength model. Finally show the results we get in this challenge. </p>

<h2>Commonly used encoding approaches</h2>
<h4>BOW(Bag of Words)</h4>
<p>Bag of words is an approach which can reduce the dimension of features processed from raw data. The brief concept can be devided into two parts, one is to decide the criteria of categorization and the other is to generate histogram base on the criteria:</br>
<i>Suppose we have already processed our raw data (audio signal) and get the N<sub>x</sub>D dimension features.</i>  
<h5>Decide the criteria of cluster-categorization</h5>
Sometimes we also say it's just like making a vocabulary codebook, which can later be used at counting the amount of each word.<br/> 
The idea started at using <a href="https://www.wikiwand.com/en/K-means_clustering">kmeans</a> method to generate numbers of k centrol points of k-clusters respectively. If nowadays we have mutiple features, F<sub>i</sub>, whose dimension are all N<sub>x</sub>D, we can randomly sample equal amount of rows from F<sub>i</sub> and generate the center point of each cluster base on the information in different features. In this way, the center point we create of each cluster can be more valid on different feature, and let the later categorized-result(histogram) to be more representative and convincing.
<h5>Generate histogram</h5>
After we got the center point of each cluster, we can categorize our features into different clusters. Each features, F<sub>i</sub>, will have a categorization result, showing the amount of vectors belongs to each cluster.(Due to the dimension of F<sub>i</sub> is N<sub>x</sub>D, we can know that there are totally N vectors with length D in the feature F<sub>i</sub>). Finally, the 'voting' result can be seen as a histogram, which x-axis represents k-cluster and y-axis represents the number of vectors belongs to each cluster.</br>
The generated histogram is then used to describe the origianl features, which reduce the dimension from N<sub>x</sub>D to 1<sub>x</sub>D. </br>
<p><b>In short, BOW approach can help us to encode the feature into a more representative while low-dimension result.</b></p>
</br>
Here's the flow:</br>
<img src="/images/Interspeech_2017/BOW.png" alt="model-nlor" />


<h4>GMM and Fisher Vector</h4>
<p>Another much more popularly used encoding aproach is Gaussian Mixture Model(GMM) followed by Fisher Vector. </br>
The <a href="https://www.wikiwand.com/en/Mixture_model">GMM</a> is like a more extended version of kmeans-clustering, it represents a cluster not using a center point but a gaussian distribution with correspnding weight. Therefore, with our features, F<sub>i</sub>, in dimension N<sub>x</sub>D, we can expect that we will get the D amount of set of Gaissian Distribution. In each set, there will be the number of K gaussian distribution as we set the number of clusters to be K. We all know that in order to describe a gaussian distribution, we have to specify its mean and variance, so after generating the Gaussian Mixture Model of our k-cluster, we will have a matrix of Mean<sub>DxK</sub> and a matrix of Covarience<sub>DxK</sub>. Additionally, to describe the relationship between k gaussian distribution, we will have the posterior value and a matrix of Prior<sub>Kx1</sub>(which could also be considered as the weight between k gaussian distribution).</br></p>
<p>After we build our GMM, we can now encode our features, F<sub>i</sub>, base on the Mean<sub>DxK</sub>,Covarience<sub>DxK</sub>, posterier, and Prior<sub>Kx1</sub>. The encoded result is what we called Fisher Vector.(a special case of general <a href = "https://www.wikiwand.com/en/Fisher_kernel">Fisher Kernel</a>)</br>
When starting encoding our features, F<sub>i</sub>(<sub>NxD</sub>), we will pick out one feature(N<sub>x</sub>1) at each time, and see which set of gaussian distribution is more similar to itself. After finding out that set, it will modify the prior between K gaussian distribution in the set, in order to fit the feature better. Therefore, the encoded result of one feature is the matrix of prior value along with posterior, which dimension should be K<sub>x</sub>2. After finishing each feature in the F<sub>i</sub>, we will get the Fisher Vector with dimension of D<sub>x</sub>K<sub>x</sub>2.</br>

<p>The Fisher Vector is then used to describe the origianl features. We can see that the original dimension is N<sub>x</sub>D while the encoded result is D<sub>x</sub>K<sub>x</sub>2, usually K will smaller than N, so the encoded reesult will decrease the dimension and since the representation of gaussian distrution is more complicate, use it as the description of a cluster will be more convincing. That is why Fisher Vector is used more popularly when encoding the features.</br></p>
Here's the flow:</br>
<img src="/images/Interspeech_2017/FV.png" alt="model-nlor" />

<h4>Strength Model</h4>




<!-- 
Here's the illustration: </p>
<p><img src="/images/retrieval/illustration.png" alt="illustration" /></p>
<p>The blue box represents the ground truth, while the yellow stands for positive recall, red for negative recall.</p>

<h2>Overview:</h2>
<ol>
  <li>Natural Language Object Retrieval </li>
  <li>Grounding with supervised training + multi-task loss</li>
  <li>Grounding + region proposal network</li>
</ol>

<h4>1. Natural Language Object Retrieval, inspired by <a href="http://arxiv.org/abs/1511.04164">Ronghang Hu's work</a></h4>
<p>This work was appeared in cvpr 2016. It extend the previous work, <a href="https://arxiv.org/abs/1411.4389">LRCN</a>, use 
the same way to generate caption. Compare the predicted caption with the query, and find the most related one. I call the whole 
process "reconstruction", which means that the model try to reconstruct back the query based on the bbox feature.</br>
Here's the model:</br>
<img src="/images/retrieval/natural-language-object-retrieval-model.png" alt="model-nlor" />
Noted that the model generate the caption not onlt based on the bbox feature, but also on the context feature, though it's a relatively
 naive way to use the context information. The paper also mentions the w/o context feature perormance:</br>
<img src="/images/retrieval/exp.png" alt="exp-nlor" /></p>

<h4>2. Grounding with supervised training + multi-task loss, inspired by <a href="https://arxiv.org/abs/1511.03745">
    Anna Rohrbach's work</a></h4>
<p>This work is from the same team of UC Berkeley. It extends the work to three different models, unsupervised, semi-supervised, and 
fully supervised model. Basically, it also uses the concept of reconstruction and combine it with a more direct way: directly choose
 the most related region. Furthermore, in the unsupervised model, they also use the attention mechanism, which is used heavily in 
 image caption task.<\br>
Here, I modified the fully supervised method with an extra reconstruction loss. This make the whole model become like a multi-task 
model, which increase the performance about 2%! The following is what the model look like:<\br>
<img src="/images/retrieval/model2.png" alt="model2" />
</p>

<h2>Acknowledgement:</h2>
<p>This work is done during my Umbo CV internship. Thanks to all the umbots that fulfills my summer internship. Umbo CV really 
provides a comfortable environment for coders. I truely enjoy the life there. :)
</p>
<h2>Reference:</h2>
Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko, Trevor Darrell, <a href="http://arxiv.org/abs/1511.04164">Natural Language Object Retrieval</a><br>
Anna Rohrbach, Marcus Rohrbach, Ronghang Hu, Trevor Darrell, Bernt Schiele, <a href="https://arxiv.org/abs/1511.03745">Grounding of Textual Phrases in Images by Reconstruction </a><br>
Sahar Kazemzadeh, Vicente Ordonez Mark Matten, Tamara Berg, <a href="http://tamaraberg.com/referitgame/">ReferItGame: Referring to Objects in Photographs of Natural Scenes </a><br> -->

</article>

  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname  = 'http-w102060018w-github-io';
    var disqus_identifier = '/Interspeech_ComPareE_17';
    var disqus_title      = '';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



      </div>
    </div>
  </div>

  <footer class="center">
  <div class="measure">
    <small>
      Powered by <a href="https://jekyllrb.com/">Jekyll</a> using <a href="https://pixyll.com/">Pixyll</a> theme. Hosted on <a href="https://pages.github.com/">Github Pages</a>. <br>
      © Yuan-Hong Liao
    </small>
  </div>
</footer>

</body>
</html>
